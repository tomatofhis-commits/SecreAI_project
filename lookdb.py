import os
import chromadb
import json
import numpy as np

# ãƒ‘ã‚¹è¨­å®š
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
db_path = os.path.join(BASE_DIR, "memory_db")

class NumpyEncoder(json.JSONEncoder):
    def default(self, obj):
        if isinstance(obj, np.ndarray):
            return obj.tolist()
        return super(NumpyEncoder, self).default(obj)

try:
    client = chromadb.PersistentClient(path=db_path)
    # ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ä¸€è¦§ã‚’å–å¾—
    collections = client.list_collections()
    
    if not collections:
        print("âŒ è¨˜æ†¶ãƒ‡ãƒ¼ã‚¿ï¼ˆã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ï¼‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
    else:
        target_name = "long_term_memory" # æŒ‡å®šã®åå‰
        collection = client.get_collection(name=target_name)
        
        # å…¨ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        results = collection.get()
        
        docs = results.get("documents", [])
        metas = results.get("metadatas", [])
        ids = results.get("ids", [])

        if not docs:
            print("è¨˜æ†¶ã¯ç©ºã§ã™ã€‚")
        else:
            # --- 1. ãƒ‡ãƒ¼ã‚¿ã‚’æœ€æ–°é †ï¼ˆunixã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—é™é †ï¼‰ã«ä¸¦ã¹æ›¿ãˆ ---
            combined = []
            for i in range(len(docs)):
                combined.append({
                    "id": ids[i],
                    "doc": docs[i],
                    "meta": metas[i] if metas else {}
                })
            
            # unixã®å€¤ã§ã‚½ãƒ¼ãƒˆï¼ˆå€¤ãŒãªã„å ´åˆã¯0ã«ã™ã‚‹ï¼‰
            combined.sort(key=lambda x: x["meta"].get("unix", 0), reverse=True)

            # --- 2. ã‚³ãƒ³ã‚½ãƒ¼ãƒ«è¡¨ç¤º ---
            print(f"\n=== {target_name} ã®ä¸­èº« (æœ€æ–°é †) ===")
            for item in combined:
                date_str = item["meta"].get("timestamp") or item["meta"].get("date") or "æ—¥æ™‚ä¸æ˜"
                # IDã¨æ—¥æ™‚ã‚’è¡¨ç¤ºã—ã¦ã‹ã‚‰ã€å†…å®¹ã‚’è¡¨ç¤º
                print(f"ã€{date_str} / {item['id']}ã€‘")
                print(f"{item['doc']}")
                print("-" * 50)

            # --- 3. JSON/TXTãƒ•ã‚¡ã‚¤ãƒ«ã¸ã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ ---
            # JSONä¿å­˜
            json_path = os.path.join(BASE_DIR, "memory_export.json")
            with open(json_path, "w", encoding="utf-8") as f:
                json.dump(combined, f, ensure_ascii=False, indent=4, cls=NumpyEncoder)
            
            # TXTä¿å­˜
            txt_path = os.path.join(BASE_DIR, "memory_export.txt")
            with open(txt_path, "w", encoding="utf-8") as f:
                f.write(f"--- SecreAI Memory Export (Latest First) ---\n\n")
                for item in combined:
                    date_str = item["meta"].get("timestamp") or item["meta"].get("date") or "æ—¥æ™‚ä¸æ˜"
                    f.write(f"æ—¥æ™‚: {date_str}\nID: {item['id']}\nå†…å®¹: {item['doc']}\n")
                    f.write("-" * 30 + "\n")

            print(f"\nâœ… ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã—ã¾ã—ãŸ:")
            print(f"ğŸ“ TXT : {txt_path}")
            print(f"ğŸ“ JSON: {json_path}")

except Exception as e:
    print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")